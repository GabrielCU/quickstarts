= Query Data Stored in Object Storage, e.g. S3, Azure Blob, GCS
:experimental:

== Overview

Native Object Storage (NOS) is a Vantage feature that allows you to query data stored in files in object storage such as AWS S3, Google GCS, Azure Blob or on-prem implementations. It's useful in scenarios where you want to explore data without building a data pipeline to bring it into Vantage. 

== Prerequsites

You need access to a Teradata Vantage instance. NOS is enabled in all Vantage editions from Vantage Express through Developer, DYI to Vantage as a Service. If you need a new instance of Vantage the easiest way to start is to xref:getting.started.vmware.adoc[install Vantage Express on your local machine].

== Explore data with NOS

NOTE: Currently, NOS support CSV, JSON (as array or new-line delimited), and Parquet data formats.

Let's say you have a dataset stored as CSV files in an S3 bucket. You want to explore the dataset before you decide if you want to bring it into Vantage. For this scenario, we are going to use a public dataset published by Teradata that contains river flow data collected by the
U.S. Geological Survey. The bucket is at https://td-usgs-public.s3.amazonaws.com/.

Let's first have a look at sample CSV data. Here, we take 10 first rows that Vantage will fetch from the bucket:

[source, sql]
----
SELECT top 10 payload..* FROM (
	LOCATION='/s3/td-usgs-public.s3.amazonaws.com/CSVDATA/'
) AS d;
----

Here is what I've got:

image::csv.result.png[Select Results, width=400]

We have got plenty of numbers, but what do they mean? To answer this question, we will ask Vantage to detect the schema of the CSV files:

[source, sql]
----
SELECT * FROM (
	LOCATION='/s3/td-usgs-public.s3.amazonaws.com/CSVDATA/'
	RETURNTYPE='NOSREAD_SCHEMA'
) AS d;
----

Vantage will now fetch a data sample to analyze the schema and return results:

image::csv.schema.png[CSV Schema, width=800]

We see that the CSV files have 7 columns. For each column, we get the name, the datatype and the file coordinates that were used to infer the schema.

== Query data with NOS

Now that we know the schema, we can work with the dataset as if it was a regular SQL table. To prove the point, let's try to do some data aggregation. Let's get an average temperature per site.

[source, sql]
----
SELECT AVG(Payload..Temp) FROM (
	LOCATION='/s3/td-usgs-public.s3.amazonaws.com/CSVDATA/'
) AS d GROUP BY Payload..site_no
----

Result:

image::csv.aggregation.png[CSV Aggregation, width=400]

Note how we still have to dereference CSV columns with `Payload..`. To make our experience more similar to a table we can define a foreign table:

[source, sql]
----
-- if you are running this sample as dbc user you will not have permissions
-- to create a table in dbc database. Instead, create a new database and use
-- the newly create database to create a foreign table

CREATE DATABASE Riverflow
    AS PERMANENT = 60000000,
    SPOOL = 120000000;

CREATE FOREIGN TABLE Riverflow.riverflow
    USING ( LOCATION('/s3/td-usgs-public.s3.amazonaws.com/CSVDATA/') );

SELECT top 10 * FROM Riverflow.riverflow
----

Result:

image::csv.foreign.table.select.png[CSV Aggregation, width=800]

This time, the `SELECT` statement looks like a regular select against an in-database table. Also, the returned data uses column names from the CSV file. No need to dereference with `Payload..`. There is still an issue though. The query was still slow. There an easy way to bring the CSV data into Vantage to speed things up. Read to on to find out how.

== Load data from NOS into Vantage

Querying object storage takes time. What if you decided that the data looks interesting and you want to do some more analysis with a solution that will you quicker answers? The good news is that data returned with NOS can be used as a source for `CREATE TABLE` statements. Assuming you have `CREATE TABLE` privilege, you will be able to run:

IMPORTANT: This query assumes you created database `Riverflow` and a foreign table called `Riverflow.riverflow` in the previous step.

[source, sql]
----

-- This query assumes you created database `Riverflow` 
-- and a foreign table called `Riverflow.riverflow` in the previous step.

CREATE MULTISET TABLE 
    Riverflow.riverflow_native(site_no, Flow, GageHeight, datetime)
AS (
    SELECT site_no, Flow, GageHeight, datetime FROM Riverflow.riverflow
) WITH DATA
NO PRIMARY INDEX;

SELECT TOP 10 * FROM Riverflow.riverflow_native;
----

Result:

image::csv.data.import.png[CSV Aggregation, width=400]

This time, the `SELECT` query returned in less than a second as it answered the query using data that was already on Vantage nodes. There was no need to fetch the data from the bucket.

== Access private buckets

So far, we have used a public bucket. What if you have a private bucket? How do you tell Vantage what credentials it should use?

It is possible to inline your credentials directly into your query:

[source, sql]
----
SELECT top 10 payload..* FROM (
	LOCATION='/s3/td-usgs-public.s3.amazonaws.com/CSVDATA/'
    AUTHORIZATION='{"ACCESS_ID":"","ACCESS_KEY":""}'
) AS d;
----

Entering these credentials all the time can be tedious and less secure. In Vantage, you can create an authorization object that will serve as a container for your credentials:

[source, sql]
----
CREATE AUTHORIZATION aws_authorization
    USER 'YOUR-ACCESS-KEY-ID'
    PASSWORD 'YOUR-SECRET-ACCESS-KEY';
----

You can then reference your authorization object when you create a foreign table:

[source, sql]
----
CREATE FOREIGN TABLE Riverflow.riverflow, EXTERNAL SECURITY aws_authorization
    USING ( LOCATION('/s3/td-usgs-public.s3.amazonaws.com/CSVDATA/') );
----

== Export data from Vantage to object storage

So far, we have talked about reading and importing data from object storage. Would it not be nice if we had a way to use SQL to export data from Vantage to object storage? This is exactly what `WRITE_NOS` function is for. Let's say we want to export data from `Riverflow.riverflow_native` table to object storage. You can do so with the following query:

[source, sql]
----
SELECT * FROM WRITE_NOS (
    ON ( SELECT * FROM Riverflow.riverflow_native )
    PARTITION BY site_no ORDER BY site_no
    USING
        LOCATION('YOUR-OBJECT-STORE-URI')
        STOREDAS('PARQUET')
        COMPRESSION('SNAPPY')
        NAMING('RANGE')
        INCLUDE_ORDERING('TRUE')
) AS d;
----

Here, we instruct Vantage to take data from `Riverflow.riverflow_native` and save it in `YOUR-OBJECT-STORE-URI` bucket using `parquet` format. The data will be split into files by `site_no` attribute. The files will be compressed.

== Summary

In this quickstart we have learned how to read data from object storage using Native Object Storage (NOS) functionality in Vantage. NOS supports reading and importing data stored in CSV, JSON and Parquet formats. NOS can also export data from Vantage to object storage.

== Next steps

* link:#[Train an ML model without leaving Teradata Vantage]
* link:#[Interact with Teradata Vantage from a Jupyter notebook]
* link:#[Query Teradata from your application using REST API]
* link:#[Connect to Teradata using JDBC from your Java application]
* link:#[Tune performance with indices]
* link:#[Load data into Teradata efficiently using Teradata Parallel Transporter (TPT)]
* link:#[Extend Teradata with user defined functions]